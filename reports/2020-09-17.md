# Report - September 17th #

## Activities/Accomplishments and Concepts/Lessons Learned ##

### Concepts:
- Learning a model (specifically, training it to learn on its own)
- realistic map designs in Unreal
- moveable actors in Unreal Engine

### Activities:
I read the article assigned by Prof. Clark. Along the way, I took super detailed notes (it felt like I had to look up every other word). I got a reasonably good understanding of the terms
and concepts used in the article. 

Some of the more helpful sites I looked up during the course of the reading:
- [Explaining time horizons](https://forum.unity.com/threads/in-depth-explanation-for-time-horizon-hyperparameter.818169/)
- [Exploitation vs Exploration, plus the bandit problem](https://www.manifold.ai/exploration-vs-exploitation-in-reinforcement-learning)
- [Explaining back propagation through time](https://machinelearningmastery.com/gentle-introduction-backpropagation-time/#:~:text=Conceptually%2C%20BPTT%20works%20by%20unrolling,and%20the%20weights%20are%20updated.)

I would love to review the following concepts:
- how gradient descent is calculated (a brief overview is enough, just want to make sure I understood)
- how parallel workers submitting their evaluations of queries back into the model helps
- What "Adam" is, in regards to BPTT.


## Issues/Problems
- Just took me a while to get through the article - it was dense and I don't have a ton of machine learning knowledge to draw from (yet :) )

## Plans
- 
